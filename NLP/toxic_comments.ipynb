{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP Toxic Comment Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project Description — Introduction:\n",
    "<br>\n",
    "\n",
    "### The Dataset:\n",
    "\n",
    "The dataset was originally featured in the Jigsaw Toxic Comment Classification Challenge. The comments represent moderated Wikipedia comments are property of Wikipedia and/or Jigsaw AI. The current project uses a simplified version of the dataset, with only 1 column representing toxicity (rather than distinguishing between obscene, threatening, severely toxic comments, etc., as in the original dataset).\n",
    "<br>\n",
    "### Technical Task:\n",
    "\n",
    "The task consists of teaching a model to classify Wikipedia comments as either toxic or non-toxic in order to automatise their moderation on the website.\n",
    "<br>\n",
    "### Data Description:\n",
    "\n",
    "Our data is labelled and contained in the `toxic_comments.csv` file. There are two columns (features) in the dataset — the comments themselves, represented as a `string` (`object`), and their toxicity rating — `0` (`False`) or `1` (`True`)\n",
    "<br>\n",
    "### Project Goal:\n",
    "\n",
    "Apply NLP techniques in order to pre-process data, teach classification models, and accurately classify comments based on the F1–score.\n",
    "<br>\n",
    "### Specific Objectives, Metrics, and Implementation Plan:\n",
    "\n",
    "**Implementation Plan:**\n",
    "\n",
    "1. EDA — downloading, cleaning, and preparing data.\n",
    "2. Teaching and testing ML models.\n",
    "3. Draw conclusions.\n",
    "\n",
    "**Metrics:**\n",
    "We would like to achieve model results with the F1–score ≥ 0.75, according to our project specifications.\n",
    "\n",
    "**Models:**\n",
    "We will be applying classification models: logistic regression, random forest, and the LightGBM classifier.\n",
    "\n",
    "In addition, our course contained specification and practice use cases of the BERT NLP technique / model, but we will use simpler models in this project given their sufficient performance and our limited computational resources.\n",
    "\n",
    "<br>\n",
    "\n",
    "### WARNING :\n",
    "\n",
    "*THE NOTEBOOK MAY CONTAIN OBSCENE AND INAPPROPRIATE CONTENT BECAUSE OF THE NATURE OF THE DATASET BEING USED. READER DISCRETION IS ADVISED.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA and Pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Note that some packages need to be additionally installed in order to run the Jupyter Notebook code. The Mac M1 chips require a special command to enable LightGBM installation (can also be run in the Terminal):\n",
    "\n",
    "```\n",
    "conda install \\\n",
    "   --yes \\\n",
    "   -c conda-forge \\\n",
    "   'lightgbm>=3.3.3'\n",
    "```"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in /Users/ana/opt/miniconda3/lib/python3.10/site-packages (1.2.0)\r\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/ana/opt/miniconda3/lib/python3.10/site-packages (from scikit-learn) (3.1.0)\r\n",
      "Requirement already satisfied: scipy>=1.3.2 in /Users/ana/opt/miniconda3/lib/python3.10/site-packages (from scikit-learn) (1.7.3)\r\n",
      "Requirement already satisfied: joblib>=1.1.1 in /Users/ana/opt/miniconda3/lib/python3.10/site-packages (from scikit-learn) (1.2.0)\r\n",
      "Requirement already satisfied: numpy>=1.17.3 in /Users/ana/opt/miniconda3/lib/python3.10/site-packages (from scikit-learn) (1.22.3)\r\n",
      "Requirement already satisfied: pymystem3 in /Users/ana/opt/miniconda3/lib/python3.10/site-packages (0.2.0)\r\n",
      "Requirement already satisfied: requests in /Users/ana/opt/miniconda3/lib/python3.10/site-packages (from pymystem3) (2.25.1)\r\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/ana/opt/miniconda3/lib/python3.10/site-packages (from requests->pymystem3) (1.26.6)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/ana/opt/miniconda3/lib/python3.10/site-packages (from requests->pymystem3) (2022.12.7)\r\n",
      "Requirement already satisfied: idna<3,>=2.5 in /Users/ana/opt/miniconda3/lib/python3.10/site-packages (from requests->pymystem3) (2.10)\r\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /Users/ana/opt/miniconda3/lib/python3.10/site-packages (from requests->pymystem3) (4.0.0)\r\n",
      "Requirement already satisfied: nltk in /Users/ana/opt/miniconda3/lib/python3.10/site-packages (3.8.1)\r\n",
      "Requirement already satisfied: click in /Users/ana/opt/miniconda3/lib/python3.10/site-packages (from nltk) (8.1.3)\r\n",
      "Requirement already satisfied: joblib in /Users/ana/opt/miniconda3/lib/python3.10/site-packages (from nltk) (1.2.0)\r\n",
      "Requirement already satisfied: tqdm in /Users/ana/opt/miniconda3/lib/python3.10/site-packages (from nltk) (4.61.1)\r\n",
      "Requirement already satisfied: regex>=2021.8.3 in /Users/ana/opt/miniconda3/lib/python3.10/site-packages (from nltk) (2022.10.31)\r\n"
     ]
    }
   ],
   "source": [
    "# Installing libraries, if necessary:\n",
    "!pip install scikit-learn\n",
    "!pip install pymystem3\n",
    "!pip install nltk\n",
    "\n",
    "# Importing libraries and frameworks:\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import KFold\n",
    "import lightgbm as lgb\n",
    "\n",
    "from pymystem3 import Mystem\n",
    "import re\n",
    "import nltk\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 159292 entries, 0 to 159450\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count   Dtype \n",
      "---  ------  --------------   ----- \n",
      " 0   text    159292 non-null  object\n",
      " 1   toxic   159292 non-null  int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 3.6+ MB\n"
     ]
    },
    {
     "data": {
      "text/plain": "                                                text  toxic\n0  Explanation\\nWhy the edits made under my usern...      0\n1  D'aww! He matches this background colour I'm s...      0\n2  Hey man, I'm really not trying to edit war. It...      0\n3  \"\\nMore\\nI can't make any real suggestions on ...      0\n4  You, sir, are my hero. Any chance you remember...      0",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>toxic</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Explanation\\nWhy the edits made under my usern...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>D'aww! He matches this background colour I'm s...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Hey man, I'm really not trying to edit war. It...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>You, sir, are my hero. Any chance you remember...</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "None"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "0    143106\n1     16186\nName: toxic, dtype: int64"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.read_csv('toxic_comments.csv', index_col = 'Unnamed: 0')\n",
    "display(df.head(), df.info(), df['toxic'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have a dataset of approximately 160'000 entries, which is imbalanced in the target feature. We will need to bear this in mind when applying our models: we will use the automatic `class_weight = balanced` parameter, although we could also experiment with up- and down-sampling techniques.\n",
    "\n",
    "The target variable passes our sanity check — it contains values of either `0` or `1`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us check for duplicates and missing values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "False    159292\ndtype: int64"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "text     0\ntoxic    0\ndtype: int64"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df.duplicated().value_counts(), df.isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are no duplicates or missing values in the columns, and we can begin NLP data pre-processing:\n",
    "1. We will first lemmatise all the comments — remove extraneous punctuation and spaces, converting all to type `U`;\n",
    "2. We will divide the data into the training, validation, and testing datasets with a ratio of 70:15:15;\n",
    "3. We will apply vectorisation using the bag-of-words technique and the `TfidfVectorizer`, being careful not to use the `fit` method on our validation or testing dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "                                                text  toxic\n0  explanation why the edits made under my userna...      0\n1  d aww he matches this background colour i m se...      0\n2  hey man i m really not trying to edit war it s...      0\n3  more i can t make any real suggestions on impr...      0\n4  you sir are my hero any chance you remember wh...      0",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>toxic</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>explanation why the edits made under my userna...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>d aww he matches this background colour i m se...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>hey man i m really not trying to edit war it s...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>more i can t make any real suggestions on impr...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>you sir are my hero any chance you remember wh...</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Applying lemmatisation:\n",
    "\n",
    "m = Mystem()\n",
    "\n",
    "def lemmatisation(comments):\n",
    "    comments = comments.lower()\n",
    "    comments = ' '.join(m.lemmatize(comments))\n",
    "    comments = re.sub(r'[^aA-zZ]', ' ', comments)\n",
    "    comments = ' '.join(comments.split())\n",
    "    return comments\n",
    "\n",
    "df['text'] = df['text'].apply(lemmatisation)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Lemmatisation has been applied correctly.\n",
    "\n",
    "We can now split our data — because we are dealing with an imbalanced dataset, let us apply the `stratify = target` parameter in order to divide our classes equally between datasets. An example of using the `stratify` parameter is shown [here](https://gist.github.com/SHi-ON/63839f3a3647051a180cb03af0f7d0d9)."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "((111504, 1), (23894, 1), (23894, 1), (111504,), (23894,), (23894,))"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dividing into subsets:\n",
    "features = df.drop('toxic', axis = 1)\n",
    "target = df['toxic']\n",
    "\n",
    "def splitter(features, target, ratio):\n",
    "    return train_test_split(features, target, test_size = ratio, stratify=target, random_state = 42)\n",
    "\n",
    "features_train, preliminary_features_test, target_train, preliminary_target_test = splitter(features, target, 0.3)\n",
    "features_valid, features_test, target_valid, target_test = splitter(preliminary_features_test,\n",
    "                                                                              preliminary_target_test, 0.5)\n",
    "features_train.shape, features_valid.shape, features_test.shape, target_train.shape, target_valid.shape, target_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Our data has been split successfully.\n",
    "\n",
    "Next, let us convert our data to the correct value-type:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "dtype('<U5000')"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "dtype('<U5000')"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "dtype('<U5382')"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "features_train = features_train['text'].values.astype('U')\n",
    "features_valid = features_valid['text'].values.astype('U')\n",
    "features_test = features_test['text'].values.astype('U')\n",
    "\n",
    "display(features_train.dtype, features_valid.dtype, features_test.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Moving on to feature vectorisation and stop-word deletion:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "((111504, 137027), (23894, 137027), (23894, 137027))"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "count_tf_idf = TfidfVectorizer(stop_words=list(stop_words))\n",
    "\n",
    "features_train = count_tf_idf.fit_transform(features_train)\n",
    "\n",
    "features_valid = count_tf_idf.transform(features_valid)\n",
    "\n",
    "features_test = count_tf_idf.transform(features_test)\n",
    "\n",
    "features_train.shape, features_valid.shape, features_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusion:**\n",
    "\n",
    "In this section, we have lemmatised our comments and divided them into subsets, where we have accounted for class imbalance and stratified our sets. We have converted our data to the correct datasetype and deleted English-language stop-words. We have also used the bag-of-words technique in order to vectorise our comments.\n",
    "\n",
    "We can now move on to training, tuning, and testing our models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ML Models\n",
    "\n",
    "We are faced with a classification task, and we will be using logistic regression, random forest, and LightGBM frameworks / models in order to solve it.\n",
    "\n",
    "We will train the models and examine their performance on the validation dataset, train and tune them using the validation dataset if necessary, and finally test them in implementing sentiment analysis on the (entirely unseen) testing dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "Empty DataFrame\nColumns: []\nIndex: [f1_score, learning_time, prediction_time]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>f1_score</th>\n    </tr>\n    <tr>\n      <th>learning_time</th>\n    </tr>\n    <tr>\n      <th>prediction_time</th>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let us create a dataframe for storing our results:\n",
    "\n",
    "df_results = pd.DataFrame(index = ['f1_score', 'learning_time', 'prediction_time'])\n",
    "df_results"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let us now create a function in order to train our models without tuning, using the validation dataset to test the results:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "                 LogisticRegression  RandomForestClassifier  LGBMClassifier\nf1_score                    0.75188                 0.63013         0.72598\nlearning_time               6.82944               472.46407        24.19027\nprediction_time             0.00621                 3.61217         0.40085",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>LogisticRegression</th>\n      <th>RandomForestClassifier</th>\n      <th>LGBMClassifier</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>f1_score</th>\n      <td>0.75188</td>\n      <td>0.63013</td>\n      <td>0.72598</td>\n    </tr>\n    <tr>\n      <th>learning_time</th>\n      <td>6.82944</td>\n      <td>472.46407</td>\n      <td>24.19027</td>\n    </tr>\n    <tr>\n      <th>prediction_time</th>\n      <td>0.00621</td>\n      <td>3.61217</td>\n      <td>0.40085</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.float_format', '{:.5f}'.format)\n",
    "\n",
    "def modelling(model, features_train, target_train, features_valid, target_valid):\n",
    "    start_time = time.time()\n",
    "    model.fit(features_train, target_train)\n",
    "    learning_time = time.time() - start_time\n",
    "    predictions = model.predict(features_valid)\n",
    "    prediction_time = time.time() - learning_time - start_time\n",
    "    f1 = f1_score(target_valid, predictions)\n",
    "    return [f1, learning_time, prediction_time]\n",
    "\n",
    "# We are using practically default parameters in our models:\n",
    "df_results = df_results.assign(LogisticRegression = modelling(LogisticRegression(random_state = 42, class_weight='balanced'), features_train, target_train, features_valid, target_valid))\n",
    "df_results = df_results.assign(RandomForestClassifier = modelling(RandomForestClassifier(random_state = 42, class_weight='balanced'), features_train, target_train, features_valid, target_valid))\n",
    "df_results = df_results.assign(LGBMClassifier = modelling(lgb.LGBMClassifier(random_state = 42, boosting_type='gbdt', is_unbalance=True), features_train, target_train, features_test, target_test))\n",
    "\n",
    "df_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our simplest model (logistic regression) has already allowed us to achieve the necessary F1–score, and it is also the fastest performing model. We could try to improve on it using a different `solver` parameter. [This](https://stackoverflow.com/questions/38640109/logistic-regression-python-solvers-definitions) post recommends either `liblinear` or `sag` for relatively large datasets — let us compare those:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "                 LogisticRegression_default  LogisticRegression_liblinear  \\\nf1_score                            0.75188                       0.75147   \nlearning_time                       6.61875                       1.64428   \nprediction_time                     0.00717                       0.00552   \n\n                 LogisticRegression_sag  \nf1_score                        0.75147  \nlearning_time                   3.49507  \nprediction_time                 0.00302  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>LogisticRegression_default</th>\n      <th>LogisticRegression_liblinear</th>\n      <th>LogisticRegression_sag</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>f1_score</th>\n      <td>0.75188</td>\n      <td>0.75147</td>\n      <td>0.75147</td>\n    </tr>\n    <tr>\n      <th>learning_time</th>\n      <td>6.61875</td>\n      <td>1.64428</td>\n      <td>3.49507</td>\n    </tr>\n    <tr>\n      <th>prediction_time</th>\n      <td>0.00717</td>\n      <td>0.00552</td>\n      <td>0.00302</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results_lr = pd.DataFrame(index = ['f1_score', 'learning_time', 'prediction_time'])\n",
    "df_results_lr = df_results_lr.assign(LogisticRegression_default = modelling(LogisticRegression(random_state = 42, class_weight='balanced'), features_train, target_train, features_valid, target_valid))\n",
    "df_results_lr = df_results_lr.assign(LogisticRegression_liblinear = modelling(LogisticRegression(random_state = 42, class_weight='balanced', solver = 'liblinear'), features_train, target_train, features_valid, target_valid))\n",
    "df_results_lr = df_results_lr.assign(LogisticRegression_sag = modelling(LogisticRegression(random_state = 42, class_weight='balanced', solver = 'sag'), features_train, target_train, features_valid, target_valid))\n",
    "df_results_lr"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Both of the new solvers show better performance on the F1–score, and the much shorter learning time of the `liblinear` solver makes it the preferred option.\n",
    "\n",
    "Let's add the `liblinear` model to our results table:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "                 LogisticRegression  RandomForestClassifier  LGBMClassifier  \\\nf1_score                    0.75188                 0.63013         0.72598   \nlearning_time               6.82944               472.46407        24.19027   \nprediction_time             0.00621                 3.61217         0.40085   \n\n                 LogisticRegression_tuned  \nf1_score                          0.75147  \nlearning_time                     1.54695  \nprediction_time                   0.00682  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>LogisticRegression</th>\n      <th>RandomForestClassifier</th>\n      <th>LGBMClassifier</th>\n      <th>LogisticRegression_tuned</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>f1_score</th>\n      <td>0.75188</td>\n      <td>0.63013</td>\n      <td>0.72598</td>\n      <td>0.75147</td>\n    </tr>\n    <tr>\n      <th>learning_time</th>\n      <td>6.82944</td>\n      <td>472.46407</td>\n      <td>24.19027</td>\n      <td>1.54695</td>\n    </tr>\n    <tr>\n      <th>prediction_time</th>\n      <td>0.00621</td>\n      <td>3.61217</td>\n      <td>0.40085</td>\n      <td>0.00682</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results = df_results.assign(LogisticRegression_tuned = modelling(LogisticRegression(random_state = 42, class_weight='balanced', solver = 'liblinear'), features_train, target_train, features_valid, target_valid))\n",
    "df_results"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We could now also attempt to tune our two other models: random forest and the LGBM classifier. Of these, LGBM seems like a more promising option — it already performs better and faster than random forest.\n",
    "\n",
    "Let us therefore experiment with the LGBM model hyperparameters, using k-fold cross-validation on the training dataset to find the best combination:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "{'learning_rate': 0.3, 'n_estimators': 500}"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "0.7644255822406555"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "folds = KFold(n_splits = 4, shuffle = True, random_state = 42).split(features_train, target_train)\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 250, 500],\n",
    "    'learning_rate' : [0.3, 0.1, 0.01]\n",
    "    }\n",
    "\n",
    "lgbm_estimator = lgb.LGBMClassifier(random_state = 42, boosting_type='gbdt', max_depth = -1, is_unbalance = True)\n",
    "\n",
    "gsearch = GridSearchCV(estimator = lgbm_estimator, param_grid = param_grid, cv = folds, scoring = 'f1')\n",
    "lgb_model = gsearch.fit(X = features_train, y = target_train)\n",
    "\n",
    "display(lgb_model.best_params_, lgb_model.best_score_)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's now test these best hyperparameters on the validation dataset and add the result to our results table:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "<pandas.io.formats.style.Styler at 0x7f97f10e9cc0>",
      "text/html": "<style type=\"text/css\">\n#T_d102d_row0_col0 {\n  background-color: #482c57;\n  color: #f1f1f1;\n}\n#T_d102d_row0_col1 {\n  background-color: #edd0ca;\n  color: #000000;\n}\n#T_d102d_row0_col2, #T_d102d_row1_col0, #T_d102d_row3_col1, #T_d102d_row3_col2 {\n  background-color: #edd1cb;\n  color: #000000;\n}\n#T_d102d_row1_col1, #T_d102d_row1_col2, #T_d102d_row4_col0 {\n  background-color: #2d1e3e;\n  color: #f1f1f1;\n}\n#T_d102d_row2_col0 {\n  background-color: #794678;\n  color: #f1f1f1;\n}\n#T_d102d_row2_col1 {\n  background-color: #eac7c3;\n  color: #000000;\n}\n#T_d102d_row2_col2 {\n  background-color: #e4b8b8;\n  color: #000000;\n}\n#T_d102d_row3_col0 {\n  background-color: #492d58;\n  color: #f1f1f1;\n}\n#T_d102d_row4_col1 {\n  background-color: #e1b1b4;\n  color: #000000;\n}\n#T_d102d_row4_col2 {\n  background-color: #a2618c;\n  color: #f1f1f1;\n}\n</style>\n<table id=\"T_d102d\">\n  <thead>\n    <tr>\n      <th class=\"blank level0\" >&nbsp;</th>\n      <th id=\"T_d102d_level0_col0\" class=\"col_heading level0 col0\" >f1_score</th>\n      <th id=\"T_d102d_level0_col1\" class=\"col_heading level0 col1\" >learning_time</th>\n      <th id=\"T_d102d_level0_col2\" class=\"col_heading level0 col2\" >prediction_time</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th id=\"T_d102d_level0_row0\" class=\"row_heading level0 row0\" >LogisticRegression</th>\n      <td id=\"T_d102d_row0_col0\" class=\"data row0 col0\" >0.751877</td>\n      <td id=\"T_d102d_row0_col1\" class=\"data row0 col1\" >6.829438</td>\n      <td id=\"T_d102d_row0_col2\" class=\"data row0 col2\" >0.006215</td>\n    </tr>\n    <tr>\n      <th id=\"T_d102d_level0_row1\" class=\"row_heading level0 row1\" >RandomForestClassifier</th>\n      <td id=\"T_d102d_row1_col0\" class=\"data row1 col0\" >0.630130</td>\n      <td id=\"T_d102d_row1_col1\" class=\"data row1 col1\" >472.464070</td>\n      <td id=\"T_d102d_row1_col2\" class=\"data row1 col2\" >3.612165</td>\n    </tr>\n    <tr>\n      <th id=\"T_d102d_level0_row2\" class=\"row_heading level0 row2\" >LGBMClassifier</th>\n      <td id=\"T_d102d_row2_col0\" class=\"data row2 col0\" >0.725976</td>\n      <td id=\"T_d102d_row2_col1\" class=\"data row2 col1\" >24.190273</td>\n      <td id=\"T_d102d_row2_col2\" class=\"data row2 col2\" >0.400845</td>\n    </tr>\n    <tr>\n      <th id=\"T_d102d_level0_row3\" class=\"row_heading level0 row3\" >LogisticRegression_tuned</th>\n      <td id=\"T_d102d_row3_col0\" class=\"data row3 col0\" >0.751466</td>\n      <td id=\"T_d102d_row3_col1\" class=\"data row3 col1\" >1.546955</td>\n      <td id=\"T_d102d_row3_col2\" class=\"data row3 col2\" >0.006816</td>\n    </tr>\n    <tr>\n      <th id=\"T_d102d_level0_row4\" class=\"row_heading level0 row4\" >LGBMClassifier_tuned</th>\n      <td id=\"T_d102d_row4_col0\" class=\"data row4 col0\" >0.766565</td>\n      <td id=\"T_d102d_row4_col1\" class=\"data row4 col1\" >67.843642</td>\n      <td id=\"T_d102d_row4_col2\" class=\"data row4 col2\" >1.942461</td>\n    </tr>\n  </tbody>\n</table>\n"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results = df_results.assign(LGBMClassifier_tuned = modelling(lgb.LGBMClassifier(random_state = 42, boosting_type='gbdt', is_unbalance=True, max_depth = -1, n_estimators = 500, learning_rate = 0.3), features_train, target_train, features_valid, target_valid))\n",
    "\n",
    "# Let us highlight the best results:\n",
    "cm = sns.cubehelix_palette(as_cmap = True)\n",
    "df_results.T.apply(pd.to_numeric).style.background_gradient(cmap=cm)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The tuned LGBM classifier is more than twice as slow as the out-of-the-box model, but it shows the best results so far. Given its slowness, let us forgo random forest tuning and move on to testing our 2 final models, the tuned logistic regression and the LGBM classifier, on our testing dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing\n",
    "\n",
    "Let us now test our best tuned models on the testing subset and display the results in a new dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "<pandas.io.formats.style.Styler at 0x7f98058f7cd0>",
      "text/html": "<style type=\"text/css\">\n#T_6382f_row0_col0, #T_6382f_row0_col1, #T_6382f_row0_col2 {\n  background-color: #edd1cb;\n  color: #000000;\n}\n#T_6382f_row1_col0, #T_6382f_row1_col1, #T_6382f_row1_col2 {\n  background-color: #2d1e3e;\n  color: #f1f1f1;\n}\n</style>\n<table id=\"T_6382f\">\n  <thead>\n    <tr>\n      <th class=\"blank level0\" >&nbsp;</th>\n      <th id=\"T_6382f_level0_col0\" class=\"col_heading level0 col0\" >f1_score</th>\n      <th id=\"T_6382f_level0_col1\" class=\"col_heading level0 col1\" >learning_time</th>\n      <th id=\"T_6382f_level0_col2\" class=\"col_heading level0 col2\" >prediction_time</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th id=\"T_6382f_level0_row0\" class=\"row_heading level0 row0\" >LogisticRegression_final</th>\n      <td id=\"T_6382f_row0_col0\" class=\"data row0 col0\" >0.751693</td>\n      <td id=\"T_6382f_row0_col1\" class=\"data row0 col1\" >1.718711</td>\n      <td id=\"T_6382f_row0_col2\" class=\"data row0 col2\" >0.016241</td>\n    </tr>\n    <tr>\n      <th id=\"T_6382f_level0_row1\" class=\"row_heading level0 row1\" >LGBMClassifier_final</th>\n      <td id=\"T_6382f_row1_col0\" class=\"data row1 col0\" >0.762895</td>\n      <td id=\"T_6382f_row1_col1\" class=\"data row1 col1\" >68.963549</td>\n      <td id=\"T_6382f_row1_col2\" class=\"data row1 col2\" >1.918973</td>\n    </tr>\n  </tbody>\n</table>\n"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_results = pd.DataFrame(index = ['f1_score', 'learning_time', 'prediction_time'])\n",
    "test_results = test_results.assign(LogisticRegression_final = modelling(LogisticRegression(random_state = 42, class_weight='balanced', solver = 'liblinear'), features_train, target_train, features_test, target_test))\n",
    "test_results = test_results.assign(LGBMClassifier_final = modelling(lgb.LGBMClassifier(random_state = 42, boosting_type='gbdt', is_unbalance=True, max_depth = -1, n_estimators = 500, learning_rate = 0.3), features_train, target_train, features_test, target_test))\n",
    "\n",
    "test_results.T.apply(pd.to_numeric).style.background_gradient(cmap=cm)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that our best F1–score on the test dataset was attained with the LGBM classifier, although its performance takes longer than logistic regression. Both logistic regression and our LGBM classifier achieved the necessary metric of ≥ 0.75 on the F1–score.\n",
    "\n",
    "## Outcome Discussion\n",
    "\n",
    "Our highest F1–score was achieved using the LGBM classifier with the hyperparameters:\n",
    "- `boosting_type = 'gbdt'`;\n",
    "- `is_unbalance = True`;\n",
    "- `max_depth = -1`;\n",
    "- `n_estimators = 500`;\n",
    "- `learning_rate = 0.3`;\n",
    "- `random_state = 42`.\n",
    "\n",
    "Our final result was F1–score = 0.763, which is above the necessary benchmark, showing that our model is able to successfully predict (classify) toxic comments.\n",
    "\n",
    "Our other models — logistic regression and random forest showed worse results, with random forest significantly underperforming in both F1–score and time spent on training. We would thus recommend using either the LGBM classifier or logistic regression, which works faster and whose results are comparative with the LGBM classifier.\n",
    "\n",
    "Regarding model improvements, we could recommend further hyperparameter tuning, using a wider range of options or more folds with cross-validation. We could also test out hyperparameter tuning with random forest and analyse its underperformance. In addition, other models / frameworks like CatBoost may be attempted.\n",
    "\n",
    "In terms of overall data analysis and preparation, we could test out different ways of lemmatising our data (e.g., substituting spaces with empty symbols), and we could also either down- or up-sample our data instead of using hyperparameters to off-set class-imbalance.\n",
    "\n",
    "Overall, achieving F1–score ≥ 0.75 on our testing dataset constitutes a successful task completion."
   ]
  }
 ],
 "metadata": {
  "ExecuteTimeLog": [
   {
    "duration": 583,
    "start_time": "2021-09-04T10:03:21.447Z"
   },
   {
    "duration": 1829,
    "start_time": "2021-09-04T10:03:38.787Z"
   },
   {
    "duration": 1807,
    "start_time": "2021-09-04T10:03:55.768Z"
   },
   {
    "duration": 1812,
    "start_time": "2021-09-04T10:04:17.051Z"
   },
   {
    "duration": 1823,
    "start_time": "2021-09-04T10:04:27.183Z"
   },
   {
    "duration": 647,
    "start_time": "2021-09-04T10:06:01.600Z"
   },
   {
    "duration": 224,
    "start_time": "2021-09-04T10:17:04.839Z"
   },
   {
    "duration": 200,
    "start_time": "2021-09-04T10:17:14.052Z"
   },
   {
    "duration": 568,
    "start_time": "2021-09-04T10:17:35.552Z"
   },
   {
    "duration": 5,
    "start_time": "2021-09-04T10:18:35.862Z"
   },
   {
    "duration": 77,
    "start_time": "2021-09-04T10:18:46.433Z"
   },
   {
    "duration": 31,
    "start_time": "2021-09-04T10:18:48.797Z"
   },
   {
    "duration": 9,
    "start_time": "2021-09-04T10:19:34.892Z"
   },
   {
    "duration": 206,
    "start_time": "2021-09-04T10:20:05.918Z"
   },
   {
    "duration": 570,
    "start_time": "2021-09-04T10:20:30.120Z"
   },
   {
    "duration": 229,
    "start_time": "2021-09-04T10:20:33.499Z"
   },
   {
    "duration": 232,
    "start_time": "2021-09-04T10:20:40.360Z"
   },
   {
    "duration": 8,
    "start_time": "2021-09-04T10:38:23.649Z"
   },
   {
    "duration": 386,
    "start_time": "2021-09-04T10:40:45.928Z"
   },
   {
    "duration": 410,
    "start_time": "2021-09-04T10:40:53.566Z"
   },
   {
    "duration": 412,
    "start_time": "2021-09-04T10:41:09.871Z"
   },
   {
    "duration": 757,
    "start_time": "2021-09-04T10:41:34.736Z"
   },
   {
    "duration": 1084,
    "start_time": "2021-09-04T10:42:21.495Z"
   },
   {
    "duration": 101800,
    "start_time": "2021-09-04T10:43:08.133Z"
   },
   {
    "duration": 1051,
    "start_time": "2021-09-04T10:45:30.471Z"
   },
   {
    "duration": 1060,
    "start_time": "2021-09-04T10:45:57.418Z"
   },
   {
    "duration": 12659,
    "start_time": "2021-09-04T10:46:09.173Z"
   },
   {
    "duration": 1514,
    "start_time": "2021-09-04T10:46:59.013Z"
   },
   {
    "duration": 1985,
    "start_time": "2021-09-04T10:47:04.718Z"
   },
   {
    "duration": 1767,
    "start_time": "2021-09-04T10:47:21.250Z"
   },
   {
    "duration": 4736,
    "start_time": "2021-09-04T10:47:44.263Z"
   },
   {
    "duration": 1067,
    "start_time": "2021-09-04T10:51:11.828Z"
   },
   {
    "duration": 640,
    "start_time": "2021-09-04T10:51:12.897Z"
   },
   {
    "duration": 6,
    "start_time": "2021-09-04T10:51:13.539Z"
   },
   {
    "duration": 51,
    "start_time": "2021-09-04T10:51:13.547Z"
   },
   {
    "duration": 255,
    "start_time": "2021-09-04T10:51:13.600Z"
   },
   {
    "duration": 268,
    "start_time": "2021-09-04T10:54:19.341Z"
   },
   {
    "duration": 1056,
    "start_time": "2021-09-04T10:54:26.377Z"
   },
   {
    "duration": 1318,
    "start_time": "2021-09-04T10:54:36.300Z"
   },
   {
    "duration": 909,
    "start_time": "2021-09-04T10:54:37.620Z"
   },
   {
    "duration": 6,
    "start_time": "2021-09-04T10:54:38.531Z"
   },
   {
    "duration": 30,
    "start_time": "2021-09-04T10:54:38.539Z"
   },
   {
    "duration": 253,
    "start_time": "2021-09-04T10:54:38.570Z"
   },
   {
    "duration": 113676,
    "start_time": "2021-09-04T10:54:38.825Z"
   },
   {
    "duration": 82915,
    "start_time": "2021-09-04T10:56:47.324Z"
   },
   {
    "duration": 247,
    "start_time": "2021-09-04T11:02:17.489Z"
   },
   {
    "duration": 30,
    "start_time": "2021-09-04T11:02:51.777Z"
   },
   {
    "duration": 49,
    "start_time": "2021-09-04T11:04:48.386Z"
   },
   {
    "duration": 48,
    "start_time": "2021-09-04T11:05:21.970Z"
   },
   {
    "duration": 81,
    "start_time": "2021-09-04T11:05:42.290Z"
   },
   {
    "duration": 83,
    "start_time": "2021-09-04T11:05:55.779Z"
   },
   {
    "duration": 47,
    "start_time": "2021-09-04T11:06:08.483Z"
   },
   {
    "duration": 133,
    "start_time": "2021-09-04T11:12:19.292Z"
   },
   {
    "duration": 14,
    "start_time": "2021-09-04T11:15:36.801Z"
   },
   {
    "duration": 10,
    "start_time": "2021-09-04T11:15:55.460Z"
   },
   {
    "duration": 11,
    "start_time": "2021-09-04T11:18:26.257Z"
   },
   {
    "duration": 3,
    "start_time": "2021-09-04T11:20:29.637Z"
   },
   {
    "duration": 611,
    "start_time": "2021-09-04T11:23:32.811Z"
   },
   {
    "duration": 612,
    "start_time": "2021-09-04T11:24:26.735Z"
   },
   {
    "duration": 651,
    "start_time": "2021-09-04T11:24:35.884Z"
   },
   {
    "duration": 7,
    "start_time": "2021-09-04T11:24:49.340Z"
   },
   {
    "duration": 626,
    "start_time": "2021-09-04T11:27:03.200Z"
   },
   {
    "duration": 509,
    "start_time": "2021-09-04T12:39:50.360Z"
   },
   {
    "duration": 5,
    "start_time": "2021-09-04T12:42:05.896Z"
   },
   {
    "duration": 247,
    "start_time": "2021-09-04T12:43:08.422Z"
   },
   {
    "duration": 4,
    "start_time": "2021-09-04T12:43:31.505Z"
   },
   {
    "duration": 1441,
    "start_time": "2021-09-04T12:45:22.938Z"
   },
   {
    "duration": 669,
    "start_time": "2021-09-04T12:45:24.381Z"
   },
   {
    "duration": 6,
    "start_time": "2021-09-04T12:45:25.053Z"
   },
   {
    "duration": 50,
    "start_time": "2021-09-04T12:45:25.061Z"
   },
   {
    "duration": 273,
    "start_time": "2021-09-04T12:45:25.113Z"
   },
   {
    "duration": 110704,
    "start_time": "2021-09-04T12:45:25.388Z"
   },
   {
    "duration": 55,
    "start_time": "2021-09-04T12:47:16.094Z"
   },
   {
    "duration": 346,
    "start_time": "2021-09-04T12:47:16.151Z"
   },
   {
    "duration": -203,
    "start_time": "2021-09-04T12:47:16.703Z"
   },
   {
    "duration": -204,
    "start_time": "2021-09-04T12:47:16.705Z"
   },
   {
    "duration": 228,
    "start_time": "2021-09-04T12:49:58.881Z"
   },
   {
    "duration": 5,
    "start_time": "2021-09-04T12:50:06.010Z"
   },
   {
    "duration": 1848,
    "start_time": "2021-09-04T12:50:09.856Z"
   },
   {
    "duration": 9,
    "start_time": "2021-09-04T12:51:06.019Z"
   },
   {
    "duration": 1318,
    "start_time": "2021-09-04T12:53:01.665Z"
   },
   {
    "duration": 671,
    "start_time": "2021-09-04T12:53:02.985Z"
   },
   {
    "duration": 7,
    "start_time": "2021-09-04T12:53:03.658Z"
   },
   {
    "duration": 45,
    "start_time": "2021-09-04T12:53:03.667Z"
   },
   {
    "duration": 267,
    "start_time": "2021-09-04T12:53:03.713Z"
   },
   {
    "duration": 110165,
    "start_time": "2021-09-04T12:53:03.982Z"
   },
   {
    "duration": 61,
    "start_time": "2021-09-04T12:54:54.149Z"
   },
   {
    "duration": 9,
    "start_time": "2021-09-04T12:54:56.873Z"
   },
   {
    "duration": 36,
    "start_time": "2021-09-04T12:55:07.195Z"
   },
   {
    "duration": 9516,
    "start_time": "2021-09-04T12:55:12.233Z"
   },
   {
    "duration": 296,
    "start_time": "2021-09-04T12:55:22.638Z"
   },
   {
    "duration": 253,
    "start_time": "2021-09-04T13:02:02.100Z"
   },
   {
    "duration": 256,
    "start_time": "2021-09-04T13:02:11.344Z"
   },
   {
    "duration": 4,
    "start_time": "2021-09-04T13:02:15.515Z"
   },
   {
    "duration": 61,
    "start_time": "2021-09-04T13:02:20.726Z"
   },
   {
    "duration": 8,
    "start_time": "2021-09-04T13:02:22.422Z"
   },
   {
    "duration": 4,
    "start_time": "2021-09-04T13:02:27.049Z"
   },
   {
    "duration": 1713,
    "start_time": "2021-09-04T13:02:36.357Z"
   },
   {
    "duration": 1262,
    "start_time": "2021-09-04T13:03:09.402Z"
   },
   {
    "duration": 709,
    "start_time": "2021-09-04T13:03:10.666Z"
   },
   {
    "duration": 17,
    "start_time": "2021-09-04T13:03:11.378Z"
   },
   {
    "duration": 35,
    "start_time": "2021-09-04T13:03:11.397Z"
   },
   {
    "duration": 282,
    "start_time": "2021-09-04T13:03:11.434Z"
   },
   {
    "duration": 111211,
    "start_time": "2021-09-04T13:03:11.718Z"
   },
   {
    "duration": 62,
    "start_time": "2021-09-04T13:05:02.931Z"
   },
   {
    "duration": 10,
    "start_time": "2021-09-04T13:05:26.119Z"
   },
   {
    "duration": 8,
    "start_time": "2021-09-04T13:05:38.027Z"
   },
   {
    "duration": 18,
    "start_time": "2021-09-04T13:05:47.562Z"
   },
   {
    "duration": 16,
    "start_time": "2021-09-04T13:05:55.406Z"
   },
   {
    "duration": 16,
    "start_time": "2021-09-04T13:06:03.142Z"
   },
   {
    "duration": 2423,
    "start_time": "2021-09-04T13:06:28.946Z"
   },
   {
    "duration": 9550,
    "start_time": "2021-09-04T13:06:43.754Z"
   },
   {
    "duration": 5,
    "start_time": "2021-09-04T13:07:18.112Z"
   },
   {
    "duration": 357,
    "start_time": "2021-09-04T13:08:00.941Z"
   },
   {
    "duration": 10,
    "start_time": "2021-09-04T13:08:40.710Z"
   },
   {
    "duration": 617,
    "start_time": "2021-09-04T13:08:43.047Z"
   },
   {
    "duration": 7919,
    "start_time": "2021-09-04T13:11:10.742Z"
   },
   {
    "duration": 638,
    "start_time": "2021-09-04T13:11:30.670Z"
   },
   {
    "duration": 7740,
    "start_time": "2021-09-04T13:11:33.197Z"
   },
   {
    "duration": 641,
    "start_time": "2021-09-04T13:12:35.904Z"
   },
   {
    "duration": 388,
    "start_time": "2021-09-04T13:16:08.305Z"
   },
   {
    "duration": 8046,
    "start_time": "2021-09-04T13:16:27.582Z"
   },
   {
    "duration": 8341,
    "start_time": "2021-09-04T13:17:02.208Z"
   },
   {
    "duration": 8134,
    "start_time": "2021-09-04T13:17:30.201Z"
   },
   {
    "duration": 5,
    "start_time": "2021-09-04T13:17:50.384Z"
   },
   {
    "duration": 7,
    "start_time": "2021-09-04T13:18:02.305Z"
   },
   {
    "duration": 245,
    "start_time": "2021-09-04T13:18:12.838Z"
   },
   {
    "duration": 239,
    "start_time": "2021-09-04T13:18:37.417Z"
   },
   {
    "duration": 238,
    "start_time": "2021-09-04T13:18:43.946Z"
   },
   {
    "duration": 3,
    "start_time": "2021-09-04T13:19:35.901Z"
   },
   {
    "duration": 13,
    "start_time": "2021-09-04T13:19:44.965Z"
   },
   {
    "duration": 8696,
    "start_time": "2021-09-04T13:19:47.886Z"
   },
   {
    "duration": 7669,
    "start_time": "2021-09-04T13:20:59.667Z"
   },
   {
    "duration": 610,
    "start_time": "2021-09-04T13:21:37.923Z"
   },
   {
    "duration": 622,
    "start_time": "2021-09-04T13:21:45.298Z"
   },
   {
    "duration": 7788,
    "start_time": "2021-09-04T13:21:55.045Z"
   },
   {
    "duration": 3399179,
    "start_time": "2021-09-04T13:22:11.985Z"
   },
   {
    "duration": -555,
    "start_time": "2021-09-04T14:18:51.721Z"
   },
   {
    "duration": 8,
    "start_time": "2021-09-04T14:19:22.287Z"
   },
   {
    "duration": 6,
    "start_time": "2021-09-04T14:20:09.560Z"
   },
   {
    "duration": 42587,
    "start_time": "2021-09-04T14:20:33.438Z"
   },
   {
    "duration": 6,
    "start_time": "2021-09-04T14:21:22.318Z"
   },
   {
    "duration": 7706,
    "start_time": "2021-09-04T14:22:29.041Z"
   },
   {
    "duration": 7,
    "start_time": "2021-09-04T14:22:40.255Z"
   },
   {
    "duration": 7686,
    "start_time": "2021-09-04T14:24:10.158Z"
   },
   {
    "duration": 6,
    "start_time": "2021-09-04T14:24:24.164Z"
   },
   {
    "duration": 7665,
    "start_time": "2021-09-04T14:24:25.372Z"
   },
   {
    "duration": 7648,
    "start_time": "2021-09-04T14:24:40.386Z"
   },
   {
    "duration": 9,
    "start_time": "2021-09-04T14:24:55.750Z"
   },
   {
    "duration": 7778,
    "start_time": "2021-09-04T14:29:11.058Z"
   },
   {
    "duration": 8,
    "start_time": "2021-09-04T14:29:20.117Z"
   },
   {
    "duration": 47863,
    "start_time": "2021-09-04T14:30:13.553Z"
   },
   {
    "duration": 44442,
    "start_time": "2021-09-04T14:33:19.849Z"
   },
   {
    "duration": 43672,
    "start_time": "2021-09-04T14:34:56.791Z"
   },
   {
    "duration": 41620,
    "start_time": "2021-09-04T14:36:01.454Z"
   },
   {
    "duration": 113,
    "start_time": "2021-09-04T14:36:43.075Z"
   },
   {
    "duration": 28536,
    "start_time": "2021-09-04T14:37:35.286Z"
   },
   {
    "duration": 41788,
    "start_time": "2021-09-04T14:38:05.407Z"
   },
   {
    "duration": 41641,
    "start_time": "2021-09-04T14:44:34.496Z"
   },
   {
    "duration": 366,
    "start_time": "2021-09-04T15:07:09.864Z"
   },
   {
    "duration": 4,
    "start_time": "2021-09-04T15:07:35.506Z"
   },
   {
    "duration": 860797,
    "start_time": "2021-09-04T15:07:38.878Z"
   },
   {
    "duration": 241,
    "start_time": "2021-09-04T15:25:03.490Z"
   },
   {
    "duration": 8,
    "start_time": "2021-09-04T15:25:31.958Z"
   },
   {
    "duration": 245,
    "start_time": "2021-09-04T15:25:42.286Z"
   },
   {
    "duration": 4,
    "start_time": "2021-09-04T15:26:21.037Z"
   },
   {
    "duration": 234,
    "start_time": "2021-09-04T15:27:01.175Z"
   },
   {
    "duration": 6662,
    "start_time": "2021-09-04T15:28:31.437Z"
   },
   {
    "duration": 168,
    "start_time": "2021-09-04T15:32:49.388Z"
   },
   {
    "duration": 4,
    "start_time": "2021-09-04T15:33:04.612Z"
   },
   {
    "duration": 622020,
    "start_time": "2021-09-04T15:33:08.429Z"
   },
   {
    "duration": 1839,
    "start_time": "2021-09-04T15:44:12.853Z"
   },
   {
    "duration": 2145,
    "start_time": "2021-09-04T15:45:27.610Z"
   },
   {
    "duration": 2981,
    "start_time": "2021-09-04T15:46:14.434Z"
   },
   {
    "duration": 5811,
    "start_time": "2021-09-04T15:46:33.291Z"
   },
   {
    "duration": 1274,
    "start_time": "2021-09-04T15:47:02.271Z"
   },
   {
    "duration": 1368,
    "start_time": "2021-09-04T15:47:11.531Z"
   },
   {
    "duration": 1499,
    "start_time": "2021-09-04T15:47:25.463Z"
   },
   {
    "duration": 2232,
    "start_time": "2021-09-04T15:47:51.729Z"
   },
   {
    "duration": 8635,
    "start_time": "2021-09-04T15:47:59.813Z"
   },
   {
    "duration": 4,
    "start_time": "2021-09-04T15:48:20.462Z"
   },
   {
    "duration": 5703,
    "start_time": "2021-09-04T15:48:24.478Z"
   },
   {
    "duration": 5,
    "start_time": "2021-09-04T15:49:13.321Z"
   },
   {
    "duration": 5,
    "start_time": "2021-09-04T15:49:18.189Z"
   },
   {
    "duration": 14,
    "start_time": "2021-09-04T15:49:24.521Z"
   },
   {
    "duration": 6082,
    "start_time": "2021-09-04T15:49:40.936Z"
   },
   {
    "duration": 6129,
    "start_time": "2021-09-04T15:51:03.038Z"
   },
   {
    "duration": 34025,
    "start_time": "2021-09-04T15:51:12.885Z"
   },
   {
    "duration": 471070,
    "start_time": "2021-09-04T15:52:13.756Z"
   },
   {
    "duration": 1966,
    "start_time": "2021-09-04T16:00:06.769Z"
   },
   {
    "duration": 1887,
    "start_time": "2021-09-04T16:00:32.955Z"
   },
   {
    "duration": 329091,
    "start_time": "2021-09-04T16:00:40.813Z"
   },
   {
    "duration": 180356,
    "start_time": "2021-09-04T16:09:17.326Z"
   },
   {
    "duration": 1111,
    "start_time": "2021-09-04T16:13:09.753Z"
   },
   {
    "duration": 1885,
    "start_time": "2021-09-04T16:13:15.007Z"
   },
   {
    "duration": 4097,
    "start_time": "2021-09-04T16:13:28.003Z"
   },
   {
    "duration": 17495,
    "start_time": "2021-09-04T16:13:38.647Z"
   },
   {
    "duration": 48170,
    "start_time": "2021-09-04T16:14:00.185Z"
   },
   {
    "duration": 132685,
    "start_time": "2021-09-04T16:15:06.928Z"
   },
   {
    "duration": 249726,
    "start_time": "2021-09-04T16:17:41.543Z"
   },
   {
    "duration": 227305,
    "start_time": "2021-09-04T16:22:27.598Z"
   },
   {
    "duration": 1499,
    "start_time": "2021-09-04T16:29:08.765Z"
   },
   {
    "duration": 973,
    "start_time": "2021-09-04T16:29:10.266Z"
   },
   {
    "duration": 9,
    "start_time": "2021-09-04T16:29:11.241Z"
   },
   {
    "duration": 55,
    "start_time": "2021-09-04T16:29:11.252Z"
   },
   {
    "duration": 279,
    "start_time": "2021-09-04T16:29:11.309Z"
   },
   {
    "duration": 112794,
    "start_time": "2021-09-04T16:29:11.590Z"
   },
   {
    "duration": 64,
    "start_time": "2021-09-04T16:31:04.386Z"
   },
   {
    "duration": 2389,
    "start_time": "2021-09-04T16:31:04.452Z"
   },
   {
    "duration": 9499,
    "start_time": "2021-09-04T16:31:06.844Z"
   },
   {
    "duration": 6,
    "start_time": "2021-09-04T16:31:16.345Z"
   },
   {
    "duration": 47897,
    "start_time": "2021-09-04T16:31:16.353Z"
   },
   {
    "duration": 83,
    "start_time": "2021-09-04T16:32:04.252Z"
   },
   {
    "duration": -182,
    "start_time": "2021-09-04T16:32:04.519Z"
   },
   {
    "duration": 3378200,
    "start_time": "2021-09-04T16:32:30.538Z"
   },
   {
    "duration": -218,
    "start_time": "2021-09-04T17:28:48.958Z"
   },
   {
    "duration": 40361757,
    "start_time": "2021-09-04T18:22:00.895Z"
   },
   {
    "duration": 1332630,
    "start_time": "2021-09-05T05:35:27.602Z"
   },
   {
    "duration": 254,
    "start_time": "2021-09-05T05:58:08.665Z"
   },
   {
    "duration": 238,
    "start_time": "2021-09-05T05:58:16.036Z"
   },
   {
    "duration": 247,
    "start_time": "2021-09-05T05:58:21.625Z"
   },
   {
    "duration": 5,
    "start_time": "2021-09-05T05:58:31.991Z"
   },
   {
    "duration": 250,
    "start_time": "2021-09-05T05:58:39.961Z"
   },
   {
    "duration": 245,
    "start_time": "2021-09-05T05:58:44.124Z"
   },
   {
    "duration": 249,
    "start_time": "2021-09-05T05:58:46.339Z"
   },
   {
    "duration": 241,
    "start_time": "2021-09-05T05:58:49.618Z"
   },
   {
    "duration": 8,
    "start_time": "2021-09-05T05:58:58.077Z"
   },
   {
    "duration": 255,
    "start_time": "2021-09-05T06:00:18.677Z"
   },
   {
    "duration": 1741,
    "start_time": "2021-09-05T06:00:35.486Z"
   },
   {
    "duration": 3534,
    "start_time": "2021-09-05T06:00:59.796Z"
   },
   {
    "duration": 15918,
    "start_time": "2021-09-05T06:01:08.938Z"
   },
   {
    "duration": 31190,
    "start_time": "2021-09-05T06:01:52.259Z"
   },
   {
    "duration": 15376,
    "start_time": "2021-09-05T06:02:52.689Z"
   },
   {
    "duration": 152318,
    "start_time": "2021-09-05T06:03:18.215Z"
   },
   {
    "duration": 61311,
    "start_time": "2021-09-05T06:06:23.594Z"
   },
   {
    "duration": 297993,
    "start_time": "2021-09-05T06:08:27.293Z"
   },
   {
    "duration": 22807,
    "start_time": "2021-09-05T06:13:47.891Z"
   },
   {
    "duration": 11835,
    "start_time": "2021-09-05T06:14:31.271Z"
   },
   {
    "duration": 19206,
    "start_time": "2021-09-05T06:15:06.769Z"
   },
   {
    "duration": 8501,
    "start_time": "2021-09-05T06:19:22.954Z"
   },
   {
    "duration": 43077,
    "start_time": "2021-09-05T06:21:35.084Z"
   },
   {
    "duration": 98018,
    "start_time": "2021-09-05T06:27:36.058Z"
   },
   {
    "duration": 193226,
    "start_time": "2021-09-05T06:32:55.104Z"
   },
   {
    "duration": 142575,
    "start_time": "2021-09-05T06:37:13.900Z"
   },
   {
    "duration": 485195,
    "start_time": "2021-09-05T06:43:54.911Z"
   },
   {
    "duration": 101233,
    "start_time": "2021-09-05T06:52:37.412Z"
   },
   {
    "duration": 214679,
    "start_time": "2021-09-05T06:59:58.624Z"
   },
   {
    "duration": 405960,
    "start_time": "2021-09-05T07:18:37.300Z"
   },
   {
    "duration": 430150,
    "start_time": "2021-09-05T07:34:44.190Z"
   },
   {
    "duration": 989169,
    "start_time": "2021-09-05T07:45:46.491Z"
   },
   {
    "duration": 293063,
    "start_time": "2021-09-05T08:21:53.075Z"
   },
   {
    "duration": 517860,
    "start_time": "2021-09-05T08:40:49.989Z"
   },
   {
    "duration": 351894,
    "start_time": "2021-09-05T09:04:28.933Z"
   },
   {
    "duration": 169192,
    "start_time": "2021-09-05T09:36:59.500Z"
   },
   {
    "duration": 702039,
    "start_time": "2021-09-05T09:44:21.644Z"
   },
   {
    "duration": 1786269,
    "start_time": "2021-09-05T10:03:55.662Z"
   },
   {
    "duration": 4,
    "start_time": "2021-09-05T11:00:34.763Z"
   },
   {
    "duration": 3,
    "start_time": "2021-09-05T11:00:49.366Z"
   },
   {
    "duration": 5,
    "start_time": "2021-09-05T11:00:51.519Z"
   },
   {
    "duration": 5,
    "start_time": "2021-09-05T11:01:34.417Z"
   },
   {
    "duration": 4,
    "start_time": "2021-09-05T11:02:13.915Z"
   },
   {
    "duration": 669,
    "start_time": "2021-09-05T11:02:13.921Z"
   },
   {
    "duration": 6,
    "start_time": "2021-09-05T11:02:14.592Z"
   },
   {
    "duration": 3,
    "start_time": "2021-09-05T11:02:14.601Z"
   },
   {
    "duration": 33,
    "start_time": "2021-09-05T11:02:14.606Z"
   },
   {
    "duration": 261,
    "start_time": "2021-09-05T11:02:14.640Z"
   },
   {
    "duration": 103891,
    "start_time": "2021-09-05T11:02:14.903Z"
   },
   {
    "duration": 619,
    "start_time": "2021-09-05T11:03:58.797Z"
   },
   {
    "duration": -167,
    "start_time": "2021-09-05T11:03:59.585Z"
   },
   {
    "duration": -169,
    "start_time": "2021-09-05T11:03:59.588Z"
   },
   {
    "duration": 680,
    "start_time": "2021-09-05T11:05:19.544Z"
   },
   {
    "duration": 3321,
    "start_time": "2021-09-05T11:06:15.080Z"
   },
   {
    "duration": 16,
    "start_time": "2021-09-05T11:06:51.273Z"
   },
   {
    "duration": 21,
    "start_time": "2021-09-05T11:06:55.400Z"
   },
   {
    "duration": 46,
    "start_time": "2021-09-05T11:11:37.330Z"
   },
   {
    "duration": 7181,
    "start_time": "2021-09-05T11:12:12.712Z"
   },
   {
    "duration": 7492,
    "start_time": "2021-09-05T11:12:39.070Z"
   },
   {
    "duration": 71,
    "start_time": "2021-09-05T11:13:18.723Z"
   },
   {
    "duration": 438,
    "start_time": "2021-09-05T11:13:38.131Z"
   },
   {
    "duration": 4,
    "start_time": "2021-09-05T11:14:03.816Z"
   },
   {
    "duration": 60,
    "start_time": "2021-09-05T11:14:06.870Z"
   },
   {
    "duration": 63,
    "start_time": "2021-09-05T11:14:08.759Z"
   },
   {
    "duration": 549,
    "start_time": "2021-09-05T11:14:29.102Z"
   },
   {
    "duration": 4139,
    "start_time": "2021-09-05T11:14:32.992Z"
   },
   {
    "duration": 1272,
    "start_time": "2021-09-05T11:14:48.746Z"
   },
   {
    "duration": 4,
    "start_time": "2021-09-05T11:17:17.547Z"
   },
   {
    "duration": 84,
    "start_time": "2021-09-05T11:18:36.214Z"
   },
   {
    "duration": 178,
    "start_time": "2021-09-05T11:18:40.250Z"
   },
   {
    "duration": 80,
    "start_time": "2021-09-05T11:18:41.616Z"
   },
   {
    "duration": 90,
    "start_time": "2021-09-05T11:18:53.820Z"
   },
   {
    "duration": 38,
    "start_time": "2021-09-05T11:19:00.182Z"
   },
   {
    "duration": 4,
    "start_time": "2021-09-05T11:19:47.294Z"
   },
   {
    "duration": 1158,
    "start_time": "2021-09-05T11:20:23.533Z"
   },
   {
    "duration": 4258,
    "start_time": "2021-09-05T11:20:27.093Z"
   },
   {
    "duration": 7,
    "start_time": "2021-09-05T11:20:35.345Z"
   },
   {
    "duration": 5,
    "start_time": "2021-09-05T11:20:43.778Z"
   },
   {
    "duration": 4876,
    "start_time": "2021-09-05T11:20:45.463Z"
   },
   {
    "duration": 5083,
    "start_time": "2021-09-05T11:21:02.321Z"
   },
   {
    "duration": 4,
    "start_time": "2021-09-05T11:21:21.490Z"
   },
   {
    "duration": 4997,
    "start_time": "2021-09-05T11:22:48.452Z"
   },
   {
    "duration": 4966,
    "start_time": "2021-09-05T11:23:00.726Z"
   },
   {
    "duration": 4,
    "start_time": "2021-09-05T11:24:51.574Z"
   },
   {
    "duration": 675,
    "start_time": "2021-09-05T11:24:51.580Z"
   },
   {
    "duration": 7,
    "start_time": "2021-09-05T11:24:52.257Z"
   },
   {
    "duration": 6,
    "start_time": "2021-09-05T11:24:52.266Z"
   },
   {
    "duration": 33,
    "start_time": "2021-09-05T11:24:52.291Z"
   },
   {
    "duration": 251,
    "start_time": "2021-09-05T11:24:52.325Z"
   },
   {
    "duration": 101573,
    "start_time": "2021-09-05T11:24:52.578Z"
   },
   {
    "duration": 85,
    "start_time": "2021-09-05T11:26:34.153Z"
   },
   {
    "duration": 1233,
    "start_time": "2021-09-05T11:27:25.381Z"
   },
   {
    "duration": 671,
    "start_time": "2021-09-05T11:27:26.616Z"
   },
   {
    "duration": 7,
    "start_time": "2021-09-05T11:27:27.288Z"
   },
   {
    "duration": 5,
    "start_time": "2021-09-05T11:27:27.296Z"
   },
   {
    "duration": 36,
    "start_time": "2021-09-05T11:27:27.302Z"
   },
   {
    "duration": 274,
    "start_time": "2021-09-05T11:27:27.340Z"
   },
   {
    "duration": 103023,
    "start_time": "2021-09-05T11:27:27.615Z"
   },
   {
    "duration": 64,
    "start_time": "2021-09-05T11:29:10.640Z"
   },
   {
    "duration": 2493,
    "start_time": "2021-09-05T11:29:53.186Z"
   },
   {
    "duration": 9520,
    "start_time": "2021-09-05T11:30:00.032Z"
   },
   {
    "duration": 7,
    "start_time": "2021-09-05T11:31:13.662Z"
   },
   {
    "duration": 19726,
    "start_time": "2021-09-05T11:31:16.125Z"
   },
   {
    "duration": 51120,
    "start_time": "2021-09-05T11:31:37.072Z"
   },
   {
    "duration": 3398713,
    "start_time": "2021-09-05T11:33:44.153Z"
   },
   {
    "duration": 3375990,
    "start_time": "2021-09-05T12:37:26.626Z"
   },
   {
    "duration": 4,
    "start_time": "2021-09-05T13:47:20.102Z"
   },
   {
    "duration": 605,
    "start_time": "2021-09-05T13:47:20.108Z"
   },
   {
    "duration": 6,
    "start_time": "2021-09-05T13:47:20.715Z"
   },
   {
    "duration": 243,
    "start_time": "2021-09-05T13:47:20.723Z"
   },
   {
    "duration": 99502,
    "start_time": "2021-09-05T13:47:20.968Z"
   },
   {
    "duration": 83,
    "start_time": "2021-09-05T13:49:00.473Z"
   },
   {
    "duration": 1239,
    "start_time": "2021-09-05T13:50:01.463Z"
   },
   {
    "duration": 653,
    "start_time": "2021-09-05T13:50:02.703Z"
   },
   {
    "duration": 6,
    "start_time": "2021-09-05T13:50:03.358Z"
   },
   {
    "duration": 256,
    "start_time": "2021-09-05T13:50:03.366Z"
   },
   {
    "duration": 98966,
    "start_time": "2021-09-05T13:50:03.623Z"
   },
   {
    "duration": 53,
    "start_time": "2021-09-05T13:51:42.592Z"
   },
   {
    "duration": 2261,
    "start_time": "2021-09-05T13:51:42.647Z"
   },
   {
    "duration": 9076,
    "start_time": "2021-09-05T13:51:44.910Z"
   },
   {
    "duration": 8,
    "start_time": "2021-09-05T13:51:53.992Z"
   },
   {
    "duration": 5,
    "start_time": "2021-09-05T13:52:27.955Z"
   },
   {
    "duration": 49503,
    "start_time": "2021-09-05T13:52:33.533Z"
   },
   {
    "duration": 3402813,
    "start_time": "2021-09-05T13:53:23.038Z"
   },
   {
    "duration": 1263,
    "start_time": "2021-09-05T14:54:17.873Z"
   },
   {
    "duration": 667,
    "start_time": "2021-09-05T14:54:19.138Z"
   },
   {
    "duration": 6,
    "start_time": "2021-09-05T14:54:19.806Z"
   },
   {
    "duration": 265,
    "start_time": "2021-09-05T14:54:19.813Z"
   },
   {
    "duration": 110699,
    "start_time": "2021-09-05T14:54:20.080Z"
   },
   {
    "duration": 49,
    "start_time": "2021-09-05T14:56:10.782Z"
   },
   {
    "duration": 2366,
    "start_time": "2021-09-05T14:56:10.833Z"
   },
   {
    "duration": 9181,
    "start_time": "2021-09-05T14:56:13.201Z"
   },
   {
    "duration": 6,
    "start_time": "2021-09-05T14:56:22.391Z"
   },
   {
    "duration": 393,
    "start_time": "2021-09-05T14:56:22.399Z"
   },
   {
    "duration": -402,
    "start_time": "2021-09-05T14:56:23.196Z"
   },
   {
    "duration": 82962,
    "start_time": "2021-09-05T14:58:39.763Z"
   },
   {
    "duration": 272,
    "start_time": "2021-09-05T15:01:48.533Z"
   },
   {
    "duration": 4229899,
    "start_time": "2021-09-05T15:01:59.294Z"
   },
   {
    "duration": 729041,
    "start_time": "2021-09-05T16:27:56.694Z"
   },
   {
    "duration": 3319198,
    "start_time": "2021-09-05T16:50:41.735Z"
   },
   {
    "duration": 67689,
    "start_time": "2021-09-05T18:36:18.444Z"
   },
   {
    "duration": 4589,
    "start_time": "2021-09-05T18:40:00.921Z"
   },
   {
    "duration": 93006,
    "start_time": "2021-09-05T18:40:13.289Z"
   },
   {
    "duration": 649796,
    "start_time": "2021-09-05T18:42:14.014Z"
   },
   {
    "duration": 99224,
    "start_time": "2021-09-05T18:53:51.287Z"
   },
   {
    "duration": 30546,
    "start_time": "2021-09-05T18:56:12.219Z"
   },
   {
    "duration": 73481,
    "start_time": "2021-09-05T18:57:39.850Z"
   },
   {
    "duration": 58209,
    "start_time": "2021-09-05T18:59:09.528Z"
   },
   {
    "duration": 63634,
    "start_time": "2021-09-05T19:00:57.157Z"
   },
   {
    "duration": 43274,
    "start_time": "2021-09-05T19:02:32.395Z"
   },
   {
    "duration": 98506,
    "start_time": "2021-09-05T19:03:25.629Z"
   },
   {
    "duration": -169,
    "start_time": "2021-09-05T19:08:12.570Z"
   },
   {
    "duration": -103,
    "start_time": "2021-09-05T20:14:43.808Z"
   },
   {
    "duration": 94719,
    "start_time": "2021-09-05T20:14:47.166Z"
   },
   {
    "duration": 234,
    "start_time": "2021-09-05T20:20:38.369Z"
   },
   {
    "duration": 672,
    "start_time": "2021-09-05T20:20:50.206Z"
   },
   {
    "duration": 84330,
    "start_time": "2021-09-05T20:21:10.512Z"
   },
   {
    "duration": 81810,
    "start_time": "2021-09-05T20:22:51.057Z"
   },
   {
    "duration": 95962,
    "start_time": "2021-09-05T20:24:23.379Z"
   },
   {
    "duration": 95545,
    "start_time": "2021-09-05T20:26:31.419Z"
   },
   {
    "duration": 89389,
    "start_time": "2021-09-05T20:28:20.371Z"
   },
   {
    "duration": 94127,
    "start_time": "2021-09-05T20:30:32.615Z"
   },
   {
    "duration": 94473,
    "start_time": "2021-09-05T20:32:55.053Z"
   },
   {
    "duration": 87267,
    "start_time": "2021-09-05T20:34:40.848Z"
   },
   {
    "duration": 75614,
    "start_time": "2021-09-05T20:36:51.964Z"
   },
   {
    "duration": 126213,
    "start_time": "2021-09-05T20:38:23.295Z"
   },
   {
    "duration": 210774,
    "start_time": "2021-09-05T20:40:54.017Z"
   },
   {
    "duration": 260,
    "start_time": "2021-09-05T20:46:26.913Z"
   },
   {
    "duration": 226,
    "start_time": "2021-09-05T20:46:38.432Z"
   },
   {
    "duration": 8863,
    "start_time": "2021-09-05T20:47:16.351Z"
   },
   {
    "duration": 62556,
    "start_time": "2021-09-05T20:47:46.973Z"
   },
   {
    "duration": 87350,
    "start_time": "2021-09-05T20:48:50.964Z"
   },
   {
    "duration": 182313,
    "start_time": "2021-09-05T20:50:54.335Z"
   },
   {
    "duration": 460500,
    "start_time": "2021-09-05T20:54:23.127Z"
   },
   {
    "duration": 265618,
    "start_time": "2021-09-05T21:03:20.675Z"
   },
   {
    "duration": 141197,
    "start_time": "2021-09-05T21:08:45.176Z"
   },
   {
    "duration": 201064,
    "start_time": "2021-09-05T21:13:25.883Z"
   },
   {
    "duration": 103991,
    "start_time": "2021-09-05T21:17:12.951Z"
   },
   {
    "duration": 218913,
    "start_time": "2021-09-05T21:19:10.003Z"
   },
   {
    "duration": 224234,
    "start_time": "2021-09-05T21:25:05.982Z"
   },
   {
    "duration": 200922,
    "start_time": "2021-09-05T21:39:35.387Z"
   },
   {
    "duration": 1418,
    "start_time": "2021-09-05T21:52:24.957Z"
   },
   {
    "duration": 717,
    "start_time": "2021-09-05T21:52:26.377Z"
   },
   {
    "duration": 12,
    "start_time": "2021-09-05T21:52:27.097Z"
   },
   {
    "duration": 289,
    "start_time": "2021-09-05T21:52:27.112Z"
   },
   {
    "duration": 120722,
    "start_time": "2021-09-05T21:52:27.404Z"
   },
   {
    "duration": 65,
    "start_time": "2021-09-05T21:54:28.128Z"
   },
   {
    "duration": 2530,
    "start_time": "2021-09-05T21:54:28.195Z"
   },
   {
    "duration": 10395,
    "start_time": "2021-09-05T21:54:30.728Z"
   },
   {
    "duration": 6,
    "start_time": "2021-09-05T21:54:41.126Z"
   },
   {
    "duration": 92620,
    "start_time": "2021-09-05T21:54:41.134Z"
   },
   {
    "duration": 4186505,
    "start_time": "2021-09-05T21:56:13.756Z"
   },
   {
    "duration": 168776,
    "start_time": "2021-09-05T23:06:00.263Z"
   },
   {
    "duration": 333,
    "start_time": "2021-09-05T23:08:49.041Z"
   },
   {
    "duration": 657,
    "start_time": "2021-09-06T06:02:55.027Z"
   },
   {
    "duration": 21,
    "start_time": "2021-09-06T08:06:54.347Z"
   },
   {
    "duration": 265,
    "start_time": "2021-09-08T17:06:29.271Z"
   },
   {
    "duration": 1629,
    "start_time": "2021-09-08T17:27:06.993Z"
   },
   {
    "duration": 701,
    "start_time": "2021-09-08T17:27:08.625Z"
   },
   {
    "duration": 8,
    "start_time": "2021-09-08T17:27:09.329Z"
   },
   {
    "duration": 313,
    "start_time": "2021-09-08T17:27:09.340Z"
   },
   {
    "duration": 145258,
    "start_time": "2021-09-08T17:27:12.436Z"
   },
   {
    "duration": 15077,
    "start_time": "2021-09-08T17:30:47.893Z"
   },
   {
    "duration": 6,
    "start_time": "2021-09-08T17:31:32.967Z"
   },
   {
    "duration": 691,
    "start_time": "2021-09-08T17:31:32.977Z"
   },
   {
    "duration": 18,
    "start_time": "2021-09-08T17:31:33.672Z"
   },
   {
    "duration": 289,
    "start_time": "2021-09-08T17:31:33.693Z"
   },
   {
    "duration": 147559,
    "start_time": "2021-09-08T17:31:33.984Z"
   },
   {
    "duration": 1716,
    "start_time": "2021-09-08T18:37:12.329Z"
   },
   {
    "duration": 729,
    "start_time": "2021-09-08T18:37:14.048Z"
   },
   {
    "duration": 9,
    "start_time": "2021-09-08T18:37:14.782Z"
   },
   {
    "duration": 322,
    "start_time": "2021-09-08T18:37:14.794Z"
   },
   {
    "duration": 148071,
    "start_time": "2021-09-08T18:37:15.118Z"
   },
   {
    "duration": 112,
    "start_time": "2021-09-08T18:39:43.192Z"
   },
   {
    "duration": 2793,
    "start_time": "2021-09-08T18:39:43.307Z"
   },
   {
    "duration": 12298,
    "start_time": "2021-09-08T18:39:46.102Z"
   },
   {
    "duration": 2004,
    "start_time": "2021-09-08T18:40:00.726Z"
   },
   {
    "duration": 6,
    "start_time": "2021-09-08T18:42:09.463Z"
   },
   {
    "duration": 692,
    "start_time": "2021-09-08T18:42:09.471Z"
   },
   {
    "duration": 20,
    "start_time": "2021-09-08T18:42:10.166Z"
   },
   {
    "duration": 280,
    "start_time": "2021-09-08T18:42:10.188Z"
   },
   {
    "duration": 147767,
    "start_time": "2021-09-08T18:42:10.471Z"
   },
   {
    "duration": 147,
    "start_time": "2021-09-08T18:44:38.241Z"
   },
   {
    "duration": 2181,
    "start_time": "2021-09-08T18:45:41.255Z"
   },
   {
    "duration": 1512,
    "start_time": "2021-09-08T18:45:52.922Z"
   },
   {
    "duration": 4364,
    "start_time": "2021-09-08T18:46:55.392Z"
   },
   {
    "duration": 12,
    "start_time": "2021-09-08T18:50:05.690Z"
   },
   {
    "duration": 31,
    "start_time": "2021-09-08T18:50:10.199Z"
   },
   {
    "duration": 14,
    "start_time": "2021-09-08T18:50:22.685Z"
   },
   {
    "duration": 2146,
    "start_time": "2021-09-08T18:50:47.526Z"
   },
   {
    "duration": 495,
    "start_time": "2021-09-08T18:50:54.104Z"
   },
   {
    "duration": 8931,
    "start_time": "2021-09-08T18:51:36.796Z"
   },
   {
    "duration": 12790,
    "start_time": "2021-09-08T18:51:48.734Z"
   },
   {
    "duration": 50,
    "start_time": "2021-09-08T18:52:01.527Z"
   },
   {
    "duration": 86231,
    "start_time": "2021-09-08T18:52:32.758Z"
   },
   {
    "duration": 87301,
    "start_time": "2021-09-08T19:08:58.347Z"
   },
   {
    "duration": 103201,
    "start_time": "2021-09-08T19:13:39.171Z"
   },
   {
    "duration": 77454,
    "start_time": "2021-09-08T19:21:52.389Z"
   },
   {
    "duration": 86762,
    "start_time": "2021-09-08T19:24:06.575Z"
   },
   {
    "duration": 121906,
    "start_time": "2021-09-08T19:30:00.146Z"
   },
   {
    "duration": 129,
    "start_time": "2021-09-08T19:39:42.816Z"
   },
   {
    "duration": 1927,
    "start_time": "2021-09-08T19:39:45.309Z"
   },
   {
    "duration": 7,
    "start_time": "2021-09-08T19:40:09.120Z"
   },
   {
    "duration": 726,
    "start_time": "2021-09-08T19:40:09.129Z"
   },
   {
    "duration": 27,
    "start_time": "2021-09-08T19:40:09.859Z"
   },
   {
    "duration": 301,
    "start_time": "2021-09-08T19:40:09.889Z"
   },
   {
    "duration": 152071,
    "start_time": "2021-09-08T19:40:10.192Z"
   },
   {
    "duration": 123,
    "start_time": "2021-09-08T19:42:42.266Z"
   },
   {
    "duration": 1681,
    "start_time": "2021-09-08T19:51:35.756Z"
   },
   {
    "duration": 728,
    "start_time": "2021-09-08T19:51:37.440Z"
   },
   {
    "duration": 17,
    "start_time": "2021-09-08T19:51:38.171Z"
   },
   {
    "duration": 300,
    "start_time": "2021-09-08T19:51:38.190Z"
   },
   {
    "duration": 146340,
    "start_time": "2021-09-08T19:51:38.492Z"
   },
   {
    "duration": 106,
    "start_time": "2021-09-08T19:54:04.834Z"
   },
   {
    "duration": 2694,
    "start_time": "2021-09-08T19:54:04.942Z"
   },
   {
    "duration": 12827,
    "start_time": "2021-09-08T19:54:07.639Z"
   },
   {
    "duration": 17,
    "start_time": "2021-09-08T19:54:20.470Z"
   },
   {
    "duration": 85726,
    "start_time": "2021-09-08T19:54:20.489Z"
   },
   {
    "duration": 5284446,
    "start_time": "2021-09-08T19:55:46.218Z"
   },
   {
    "duration": 1942,
    "start_time": "2021-09-18T17:02:23.599Z"
   },
   {
    "duration": 3474,
    "start_time": "2021-09-18T17:02:25.544Z"
   },
   {
    "duration": 10,
    "start_time": "2021-09-18T17:02:29.022Z"
   },
   {
    "duration": 356,
    "start_time": "2021-09-18T17:02:29.035Z"
   },
   {
    "duration": 179827,
    "start_time": "2021-09-18T17:02:29.394Z"
   },
   {
    "duration": 130,
    "start_time": "2021-09-18T17:05:29.224Z"
   },
   {
    "duration": 2905,
    "start_time": "2021-09-18T17:05:29.357Z"
   },
   {
    "duration": 15000,
    "start_time": "2021-09-18T17:05:32.264Z"
   },
   {
    "duration": 9,
    "start_time": "2021-09-18T17:06:25.193Z"
   },
   {
    "duration": 7,
    "start_time": "2021-09-18T17:07:10.352Z"
   },
   {
    "duration": 370922,
    "start_time": "2021-09-18T17:08:47.302Z"
   },
   {
    "duration": 427,
    "start_time": "2021-09-18T17:21:39.372Z"
   },
   {
    "duration": 533,
    "start_time": "2021-09-18T17:21:49.258Z"
   },
   {
    "duration": 594,
    "start_time": "2021-09-18T17:22:11.778Z"
   },
   {
    "duration": 9255,
    "start_time": "2021-09-18T17:22:17.939Z"
   },
   {
    "duration": 17,
    "start_time": "2021-09-18T17:22:37.425Z"
   },
   {
    "duration": 643,
    "start_time": "2021-09-18T17:22:52.467Z"
   },
   {
    "duration": 1674,
    "start_time": "2021-09-18T17:23:01.226Z"
   },
   {
    "duration": 600,
    "start_time": "2021-09-18T17:23:41.926Z"
   },
   {
    "duration": 21592,
    "start_time": "2021-09-18T17:23:48.283Z"
   },
   {
    "duration": 67602,
    "start_time": "2021-09-18T17:25:00.482Z"
   },
   {
    "duration": 34501,
    "start_time": "2021-09-18T17:28:12.282Z"
   },
   {
    "duration": 33266,
    "start_time": "2021-09-18T17:29:00.787Z"
   },
   {
    "duration": 32474,
    "start_time": "2021-09-18T17:29:45.090Z"
   },
   {
    "duration": 2891,
    "start_time": "2021-09-18T17:35:38.740Z"
   },
   {
    "duration": 1171,
    "start_time": "2021-09-18T17:35:41.635Z"
   },
   {
    "duration": 15,
    "start_time": "2021-09-18T17:35:42.811Z"
   },
   {
    "duration": 466,
    "start_time": "2021-09-18T17:35:42.830Z"
   },
   {
    "duration": 181870,
    "start_time": "2021-09-18T17:35:43.300Z"
   },
   {
    "duration": 203,
    "start_time": "2021-09-18T17:38:45.174Z"
   },
   {
    "duration": 3171,
    "start_time": "2021-09-18T17:38:45.380Z"
   },
   {
    "duration": 20448,
    "start_time": "2021-09-18T17:38:48.555Z"
   },
   {
    "duration": 12,
    "start_time": "2021-09-18T17:39:09.009Z"
   },
   {
    "duration": 909444,
    "start_time": "2021-09-18T17:39:09.024Z"
   },
   {
    "duration": 33165,
    "start_time": "2021-09-18T17:54:18.470Z"
   },
   {
    "duration": 5315582,
    "start_time": "2021-09-18T17:54:51.638Z"
   },
   {
    "duration": 7,
    "start_time": "2021-09-18T19:52:41.402Z"
   },
   {
    "duration": 831,
    "start_time": "2021-09-18T19:52:41.412Z"
   },
   {
    "duration": 14,
    "start_time": "2021-09-18T19:52:42.246Z"
   },
   {
    "duration": 334,
    "start_time": "2021-09-18T19:52:42.263Z"
   },
   {
    "duration": 165644,
    "start_time": "2021-09-18T19:52:42.599Z"
   },
   {
    "duration": 183,
    "start_time": "2021-09-18T19:55:28.245Z"
   },
   {
    "duration": 2031,
    "start_time": "2021-09-18T20:29:51.909Z"
   },
   {
    "duration": 3351,
    "start_time": "2021-09-18T20:29:53.943Z"
   },
   {
    "duration": 9,
    "start_time": "2021-09-18T20:29:57.299Z"
   },
   {
    "duration": 345,
    "start_time": "2021-09-18T20:29:57.311Z"
   },
   {
    "duration": 164255,
    "start_time": "2021-09-18T20:29:57.658Z"
   },
   {
    "duration": 132,
    "start_time": "2021-09-18T20:32:41.915Z"
   },
   {
    "duration": 3040,
    "start_time": "2021-09-18T20:32:42.049Z"
   },
   {
    "duration": 16004,
    "start_time": "2021-09-18T20:32:45.092Z"
   },
   {
    "duration": 9,
    "start_time": "2021-09-18T20:33:01.101Z"
   },
   {
    "duration": 320354,
    "start_time": "2021-09-18T20:33:01.114Z"
   },
   {
    "duration": 29767,
    "start_time": "2021-09-18T20:38:21.471Z"
   },
   {
    "duration": 1008327,
    "start_time": "2021-09-18T20:38:51.240Z"
   },
   {
    "duration": 513268,
    "start_time": "2021-09-18T20:58:12.197Z"
   },
   {
    "duration": 1825,
    "start_time": "2021-09-18T21:11:44.956Z"
   },
   {
    "duration": 790,
    "start_time": "2021-09-18T21:11:46.784Z"
   },
   {
    "duration": 9,
    "start_time": "2021-09-18T21:11:47.577Z"
   },
   {
    "duration": 339,
    "start_time": "2021-09-18T21:11:47.589Z"
   },
   {
    "duration": 160175,
    "start_time": "2021-09-18T21:11:47.930Z"
   },
   {
    "duration": 122,
    "start_time": "2021-09-18T21:14:28.107Z"
   },
   {
    "duration": 3008,
    "start_time": "2021-09-18T21:14:28.232Z"
   },
   {
    "duration": 14225,
    "start_time": "2021-09-18T21:14:31.242Z"
   },
   {
    "duration": 8,
    "start_time": "2021-09-18T21:14:45.471Z"
   },
   {
    "duration": 322064,
    "start_time": "2021-09-18T21:18:08.827Z"
   },
   {
    "duration": 30937,
    "start_time": "2021-09-18T21:23:30.894Z"
   },
   {
    "duration": 539525,
    "start_time": "2021-09-18T21:28:46.244Z"
   },
   {
    "duration": 433,
    "start_time": "2021-09-18T21:39:24.228Z"
   },
   {
    "duration": 1825,
    "start_time": "2021-09-18T21:47:33.458Z"
   },
   {
    "duration": 792,
    "start_time": "2021-09-18T21:47:35.286Z"
   },
   {
    "duration": 10,
    "start_time": "2021-09-18T21:47:36.081Z"
   },
   {
    "duration": 358,
    "start_time": "2021-09-18T21:47:36.093Z"
   },
   {
    "duration": 157713,
    "start_time": "2021-09-18T21:47:36.454Z"
   },
   {
    "duration": 127,
    "start_time": "2021-09-18T21:50:14.169Z"
   },
   {
    "duration": 2984,
    "start_time": "2021-09-18T21:50:14.298Z"
   },
   {
    "duration": 14334,
    "start_time": "2021-09-18T21:50:17.284Z"
   },
   {
    "duration": 8,
    "start_time": "2021-09-18T21:50:31.622Z"
   },
   {
    "duration": 348043,
    "start_time": "2021-09-18T21:50:31.632Z"
   },
   {
    "duration": 30955,
    "start_time": "2021-09-18T21:56:19.678Z"
   },
   {
    "duration": 5245439,
    "start_time": "2021-09-18T21:56:50.636Z"
   },
   {
    "duration": 542296,
    "start_time": "2021-09-18T23:24:16.077Z"
   },
   {
    "duration": 701,
    "start_time": "2021-09-18T23:33:18.375Z"
   },
   {
    "duration": 3573,
    "start_time": "2023-01-22T21:50:14.540Z"
   },
   {
    "duration": 128,
    "start_time": "2023-01-22T21:50:29.629Z"
   },
   {
    "duration": 354,
    "start_time": "2023-01-22T21:50:46.565Z"
   },
   {
    "duration": 58261,
    "start_time": "2023-01-22T21:51:58.256Z"
   },
   {
    "duration": 1110,
    "start_time": "2023-01-22T21:53:25.310Z"
   },
   {
    "duration": 4892,
    "start_time": "2023-01-22T21:54:34.876Z"
   },
   {
    "duration": 3923,
    "start_time": "2023-01-22T21:54:57.053Z"
   },
   {
    "duration": 917,
    "start_time": "2023-01-22T21:56:25.760Z"
   },
   {
    "duration": 5020,
    "start_time": "2023-01-22T21:57:12.755Z"
   },
   {
    "duration": 929,
    "start_time": "2023-01-22T21:57:50.181Z"
   },
   {
    "duration": 5320,
    "start_time": "2023-01-22T21:59:05.798Z"
   },
   {
    "duration": 2484,
    "start_time": "2023-01-22T21:59:11.121Z"
   },
   {
    "duration": 14867,
    "start_time": "2023-01-22T22:02:18.648Z"
   },
   {
    "duration": 0,
    "start_time": "2023-01-22T22:06:32.665Z"
   },
   {
    "duration": 0,
    "start_time": "2023-01-22T22:06:32.666Z"
   }
  ],
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Содержание",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "302.391px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
